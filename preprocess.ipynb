{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import prepare_dataset\n",
    "from config import Config\n",
    "from transformers import AutoModel,AutoTokenizer\n",
    "from framework.basic.tokenizer import EnglishTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Preporcess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config.from_json(\"./config/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read json method read_once failed\n"
     ]
    }
   ],
   "source": [
    "dataset = prepare_dataset(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+----------------------+---------------+----------------+---------------+---------------+----------------------------+---------------------+---------------+----------------------------+---------------------+\n",
       "| annotator_labels     | captionID     | gold_label     | pairID        | sentence1     | sentence1_binary_parse     | sentence1_parse     | sentence2     | sentence2_binary_parse     | sentence2_parse     |\n",
       "+----------------------+---------------+----------------+---------------+---------------+----------------------------+---------------------+---------------+----------------------------+---------------------+\n",
       "| ['neutral', 'enta... | 4705552913... | neutral        | 4705552913... | Two women ... | ( ( Two women ) ( ( are... | (ROOT (S (NP (CD... | The sister... | ( ( The sisters ) ( ( a... | (ROOT (S (NP (DT... |\n",
       "| ['entailment', 'e... | 4705552913... | entailment     | 4705552913... | Two women ... | ( ( Two women ) ( ( are... | (ROOT (S (NP (CD... | Two woman ... | ( ( Two woman ) ( ( are... | (ROOT (S (NP (CD... |\n",
       "| ['contradiction',... | 4705552913... | contradicti... | 4705552913... | Two women ... | ( ( Two women ) ( ( are... | (ROOT (S (NP (CD... | The men ar... | ( ( The men ) ( ( are (... | (ROOT (S (NP (DT... |\n",
       "| ['entailment', 'e... | 2407214681... | entailment     | 2407214681... | Two young ... | ( ( ( Two ( young child... | (ROOT (S (NP (NP... | Two kids i... | ( ( ( Two kids ) ( in (... | (ROOT (S (NP (NP... |\n",
       "| ['neutral', 'neut... | 2407214681... | neutral        | 2407214681... | Two young ... | ( ( ( Two ( young child... | (ROOT (S (NP (NP... | Two kids a... | ( ( ( Two kids ) ( at (... | (ROOT (S (NP (NP... |\n",
       "| ['contradiction',... | 2407214681... | contradicti... | 2407214681... | Two young ... | ( ( ( Two ( young child... | (ROOT (S (NP (NP... | Two kids i... | ( ( ( Two kids ) ( in j... | (ROOT (S (NP (NP... |\n",
       "| ['contradiction',... | 4718146904... | contradicti... | 4718146904... | A man sell... | ( ( A ( man selling ) )... | (ROOT (S (NP (DT... | A woman dr... | ( ( A woman ) ( ( ( dri... | (ROOT (S (NP (DT... |\n",
       "| ['neutral', 'enta... | 4718146904... | neutral        | 4718146904... | A man sell... | ( ( A ( man selling ) )... | (ROOT (S (NP (DT... | A man sell... | ( ( A ( man selling ) )... | (ROOT (S (NP (DT... |\n",
       "| ['entailment', 'n... | 4718146904... | entailment     | 4718146904... | A man sell... | ( ( A ( man selling ) )... | (ROOT (S (NP (DT... | A man sell... | ( ( A ( man selling ) )... | (ROOT (S (NP (DT... |\n",
       "| ['entailment', 'n... | 3980085662... | entailment     | 3980085662... | Two young ... | ( ( ( Two ( young boys ... | (ROOT (S (NP (NP... | boys play ... | ( boys ( play football ... | (ROOT (S (NP (NN... |\n",
       "| ['contradiction',... | 3980085662... | contradicti... | 3980085662... | Two young ... | ( ( ( Two ( young boys ... | (ROOT (S (NP (NP... | dog eats o... | ( dog ( ( eats out ) ( ... | (ROOT (S (NP (NN... |\n",
       "| ...                  | ...           | ...            | ...           | ...           | ...                        | ...                 | ...           | ...                        | ...                 |\n",
       "+----------------------+---------------+----------------+---------------+---------------+----------------------------+---------------------+---------------+----------------------------+---------------------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = EnglishTokenizer()\n",
    "dataset.apply_field(tokenizer.count_len,\"sentence1\", \"sent1_len\")\n",
    "dataset.apply_field(tokenizer.count_len,\"sentence2\", \"sent2_len\")\n",
    "max(dataset['sent1_len']) + max(dataset['sent2_len'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neutral': 352, 'entailment': 346, 'contradiction': 350, '-': 22})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(dataset['gold_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Bert Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(config.pretrain_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_input = bert_tokenizer(\n",
    "    text=\"I am a man of humor\",\n",
    "    text_pair=\"You are a doctor\",\n",
    "    padding=\"max_length\",\n",
    "    max_length=128,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bert_tokenizer.convert_ids_to_tokens(bert_input['input_ids'][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'i',\n",
       " 'am',\n",
       " 'a',\n",
       " 'man',\n",
       " 'of',\n",
       " 'humor',\n",
       " '[SEP]',\n",
       " 'you',\n",
       " 'are',\n",
       " 'a',\n",
       " 'doctor',\n",
       " '[SEP]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}